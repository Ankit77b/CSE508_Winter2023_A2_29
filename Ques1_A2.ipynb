{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Text extraction from file 1"
      ],
      "metadata": {
        "id": "Sr8LdLz6AKl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open the file in read mode\n",
        "file = open('/content/cranfield0001', 'r')\n",
        "\n",
        "# read the content of the file line by line\n",
        "for line in file:\n",
        "    print(line)\n",
        "\n",
        "# close the file\n",
        "file.close()\n"
      ],
      "metadata": {
        "id": "B4u18sRl5o2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Open the file for reading\n",
        "with open('/content/cranfield0001', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "#We shall use regex to extract the contents between <TITLE> and </TITLE> tags\n",
        "title = re.search('<TITLE>(.*?)</TITLE>', text, re.DOTALL).group(1)\n",
        "\n",
        "#We shall use regex to extract the contents between <TEXT> and </TEXT> tags\n",
        "text_content = re.search('<TEXT>(.*?)</TEXT>', text, re.DOTALL).group(1)\n",
        "\n",
        "# Concatenate the title and text contents with a space character\n",
        "result = title + ' ' + text_content\n",
        "\n",
        "# Save the result back to the same file\n",
        "with open('/content/cranfield0001', 'w') as file:\n",
        "    file.write(result)\n"
      ],
      "metadata": {
        "id": "NAnZFdai6eLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open the file in read mode\n",
        "file = open('/content/cranfield0001', 'r')\n",
        "\n",
        "# read the content of the file line by line\n",
        "for line in file:\n",
        "    print(line)\n",
        "\n",
        "# close the file\n",
        "file.close()\n"
      ],
      "metadata": {
        "id": "jdRdFtL-Ofb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text extraction from file 2"
      ],
      "metadata": {
        "id": "d3Nne5HNAcKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open the file in read mode\n",
        "file = open('/content/cranfield0002', 'r')\n",
        "\n",
        "# read the content of the file line by line\n",
        "for line in file:\n",
        "    print(line)\n",
        "\n",
        "# close the file\n",
        "file.close()\n"
      ],
      "metadata": {
        "id": "46AgTSnH_Sml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Open the file for reading\n",
        "with open('/content/cranfield0002', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "#We shall use regex to extract the contents between <TITLE> and </TITLE> tags\n",
        "title = re.search('<TITLE>(.*?)</TITLE>', text, re.DOTALL).group(1)\n",
        "\n",
        "#We shall use regex to extract the contents between <TEXT> and </TEXT> tags\n",
        "text_content = re.search('<TEXT>(.*?)</TEXT>', text, re.DOTALL).group(1)\n",
        "\n",
        "# Concatenate the title and text contents with a space character\n",
        "result = title + ' ' + text_content\n",
        "\n",
        "# Save the result back to the same file\n",
        "with open('/content/cranfield0002', 'w') as file:\n",
        "    file.write(result)\n"
      ],
      "metadata": {
        "id": "zpV3Gcr0_cjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open the file in read mode\n",
        "file = open('/content/cranfield0002', 'r')\n",
        "\n",
        "# read the content of the file line by line\n",
        "for line in file:\n",
        "    print(line)\n",
        "\n",
        "# close the file\n",
        "file.close()\n"
      ],
      "metadata": {
        "id": "KY5e5AfK_tt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Extraction from file 3"
      ],
      "metadata": {
        "id": "bTCxjPyzAnVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open the file in read mode\n",
        "file = open('/content/cranfield0003', 'r')\n",
        "\n",
        "# read the content of the file line by line\n",
        "for line in file:\n",
        "    print(line)\n",
        "\n",
        "# close the file\n",
        "file.close()\n"
      ],
      "metadata": {
        "id": "qlOBCunaAvBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Open the file for reading\n",
        "with open('/content/cranfield0003', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "#We shall use regex to extract the contents between <TITLE> and </TITLE> tags\n",
        "title = re.search('<TITLE>(.*?)</TITLE>', text, re.DOTALL).group(1)\n",
        "\n",
        "#We shall use regex to extract the contents between <TEXT> and </TEXT> tags\n",
        "text_content = re.search('<TEXT>(.*?)</TEXT>', text, re.DOTALL).group(1)\n",
        "\n",
        "# Concatenate the title and text contents with a space character\n",
        "result = title + ' ' + text_content\n",
        "\n",
        "# Save the result back to the same file\n",
        "with open('/content/cranfield0003', 'w') as file:\n",
        "    file.write(result)\n"
      ],
      "metadata": {
        "id": "GScwoRnhA4wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open the file in read mode\n",
        "file = open('/content/cranfield0003', 'r')\n",
        "\n",
        "# read the content of the file line by line\n",
        "for line in file:\n",
        "    print(line)\n",
        "\n",
        "# close the file\n",
        "file.close()\n"
      ],
      "metadata": {
        "id": "kCSlPU1bBA6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Extraction from file 4"
      ],
      "metadata": {
        "id": "Y-xCCVJWBF_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open the file in read mode\n",
        "file = open('/content/cranfield0004', 'r')\n",
        "\n",
        "# read the content of the file line by line\n",
        "for line in file:\n",
        "    print(line)\n",
        "\n",
        "# close the file\n",
        "file.close()\n"
      ],
      "metadata": {
        "id": "faHOkyLWBZmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Open the file for reading\n",
        "with open('/content/cranfield0004', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "#We shall use regex to extract the contents between <TITLE> and </TITLE> tags\n",
        "title = re.search('<TITLE>(.*?)</TITLE>', text, re.DOTALL).group(1)\n",
        "\n",
        "#We shall use regex to extract the contents between <TEXT> and </TEXT> tags\n",
        "text_content = re.search('<TEXT>(.*?)</TEXT>', text, re.DOTALL).group(1)\n",
        "\n",
        "# Concatenate the title and text contents with a space character\n",
        "result = title + ' ' + text_content\n",
        "\n",
        "# Save the result back to the same file\n",
        "with open('/content/cranfield0004', 'w') as file:\n",
        "    file.write(result)\n"
      ],
      "metadata": {
        "id": "ijoWB4-rBhG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open the file in read mode\n",
        "file = open('/content/cranfield0004', 'r')\n",
        "\n",
        "# read the content of the file line by line\n",
        "for line in file:\n",
        "    print(line)\n",
        "\n",
        "# close the file\n",
        "file.close()\n"
      ],
      "metadata": {
        "id": "c_Ua5I-8BoQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text extraction from file 5 "
      ],
      "metadata": {
        "id": "Yl7wpXQnBtS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open the file in read mode\n",
        "file = open('/content/cranfield0005', 'r')\n",
        "\n",
        "# read the content of the file line by line\n",
        "for line in file:\n",
        "    print(line)\n",
        "\n",
        "# close the file\n",
        "file.close()\n"
      ],
      "metadata": {
        "id": "m1Xyn7kfBy9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Open the file for reading\n",
        "with open('/content/cranfield0005', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "#We shall use regex to extract the contents between <TITLE> and </TITLE> tags\n",
        "title = re.search('<TITLE>(.*?)</TITLE>', text, re.DOTALL).group(1)\n",
        "\n",
        "#We shall use regex to extract the contents between <TEXT> and </TEXT> tags\n",
        "text_content = re.search('<TEXT>(.*?)</TEXT>', text, re.DOTALL).group(1)\n",
        "\n",
        "# Concatenate the title and text contents with a space character\n",
        "result = title + ' ' + text_content\n",
        "\n",
        "# Save the result back to the same file\n",
        "with open('/content/cranfield0005', 'w') as file:\n",
        "    file.write(result)\n"
      ],
      "metadata": {
        "id": "5xqdGbA3CCXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open the file in read mode\n",
        "file = open('/content/cranfield0005', 'r')\n",
        "\n",
        "# read the content of the file line by line\n",
        "for line in file:\n",
        "    print(line)\n",
        "\n",
        "# close the file\n",
        "file.close()\n"
      ],
      "metadata": {
        "id": "gGPVyaTZCVtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#We create a loop in the same way to extract the text from 1400 files."
      ],
      "metadata": {
        "id": "_oylJO80D9Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Loop through file names from cranfield0001 to cranfield1400\n",
        "for i in range(1, 1401):\n",
        "    # Construct file name with leading zeros\n",
        "    filename = 'cranfield'+ str(i).zfill(4)\n",
        "\n",
        "    # Open the file for reading\n",
        "    with open(filename, 'r') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # Use regex to extract the contents between <TITLE> and </TITLE> tags\n",
        "    title = re.search('<TITLE>(.*?)</TITLE>', text, re.DOTALL).group(1)\n",
        "\n",
        "    # Use regex to extract the contents between <TEXT> and </TEXT> tags\n",
        "    text_content = re.search('<TEXT>(.*?)</TEXT>', text, re.DOTALL).group(1)\n",
        "\n",
        "    # Concatenate the title and text contents with a space character\n",
        "    result = title + ' ' + text_content\n",
        "\n",
        "    # Save the result back to the same file\n",
        "    with open(filename , 'w') as file:\n",
        "        file.write(result)"
      ],
      "metadata": {
        "id": "Gnsxd7AIOx1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "85U2GnNfEQgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing important libraries\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "5WgVJW7UK4ei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcec1dcc-3894-4f41-a6b6-9c34900d7c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Preprocessing for file 1"
      ],
      "metadata": {
        "id": "wqsTCLYyL-_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file for reading\n",
        "with open('/content/cranfield0001', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "id": "h6aWbSwPLpm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase the text\n",
        "text = text.lower()\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords and punctuations, and blank space tokens\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuations = set(string.punctuation)\n",
        "tokens_filtered = [token for token in tokens if token not in stop_words and token not in punctuations and not token.isspace()]\n",
        "\n",
        "# Join the tokens back into a string\n",
        "text_processed1 = ' '.join(tokens_filtered)\n",
        "\n",
        "# Print the processed text\n",
        "print(text_processed1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxtTvAoQEZl0",
        "outputId": "907fc8bf-6605-4ea8-dabe-e289cc29bc07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "experimental investigation aerodynamics wing slipstream experimental study wing propeller slipstream made order determine spanwise distribution lift increase due slipstream different angles attack wing different free stream slipstream velocity ratios results intended part evaluation basis different theoretical treatments problem comparative span loading curves together supporting evidence showed substantial part lift increment produced slipstream due /destalling/ boundary-layer-control effect integrated remaining lift increment subtracting destalling lift found agree well potential flow theory empirical evaluation destalling effects made specific configuration experiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Preprocessing for file 2"
      ],
      "metadata": {
        "id": "HidP9KrxMKIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file for reading\n",
        "with open('/content/cranfield0002', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "id": "E0QtXPAtMQoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase the text\n",
        "text = text.lower()\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords and punctuations, and blank space tokens\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuations = set(string.punctuation)\n",
        "tokens_filtered = [token for token in tokens if token not in stop_words and token not in punctuations and not token.isspace()]\n",
        "\n",
        "# Join the tokens back into a string\n",
        "text_processed2 = ' '.join(tokens_filtered)\n",
        "\n",
        "# Print the processed text\n",
        "print(text_processed2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cff06f83-40b1-4869-b36f-981fce850fb8",
        "id": "i9j0k9RNMliU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simple shear flow past flat plate incompressible fluid small viscosity study high-speed viscous flow past two-dimensional body usually necessary consider curved shock wave emitting nose leading edge body consequently exists inviscid rotational flow region shock wave boundary layer situation arises instance study hypersonic viscous flow past flat plate situation somewhat different prandtl 's classical boundary-layer problem prandtl's original problem inviscid free stream outside boundary layer irrotational hypersonic boundary-layer problem inviscid free stream must considered rotational possible effects vorticity recently discussed ferri libby present paper simple shear flow past flat plate fluid small viscosity investigated shown problem treated boundary-layer approximation novel feature free stream constant vorticity discussion restricted two-dimensional incompressible steady flow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Processing for file 3"
      ],
      "metadata": {
        "id": "MUAhd36_MsPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file for reading\n",
        "with open('/content/cranfield0003', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "id": "6nff40OvMvdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase the text\n",
        "text = text.lower()\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords and punctuations, and blank space tokens\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuations = set(string.punctuation)\n",
        "tokens_filtered = [token for token in tokens if token not in stop_words and token not in punctuations and not token.isspace()]\n",
        "\n",
        "# Join the tokens back into a string\n",
        "text_processed3 = ' '.join(tokens_filtered)\n",
        "\n",
        "# Print the processed text\n",
        "print(text_processed3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17d033b-41ed-46c9-cfa1-b21d6579ae45",
        "id": "hEoUimJlNK4Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "boundary layer simple shear flow past flat plate boundary-layer equations presented steady incompressible flow pressure gradient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Preprocessing for file 4"
      ],
      "metadata": {
        "id": "1grrcCj2NQnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file for reading\n",
        "with open('/content/cranfield0004', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "id": "goyPtOr0NWl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase the text\n",
        "text = text.lower()\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords and punctuations, and blank space tokens\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuations = set(string.punctuation)\n",
        "tokens_filtered = [token for token in tokens if token not in stop_words and token not in punctuations and not token.isspace()]\n",
        "\n",
        "# Join the tokens back into a string\n",
        "text_processed4 = ' '.join(tokens_filtered)\n",
        "\n",
        "# Print the processed text\n",
        "print(text_processed4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb1c975d-0ca1-417f-9254-14560437a733",
        "id": "spo3vMCHNcZp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "approximate solutions incompressible laminar boundary layer equations plate shear flow two-dimensional steady boundary-layer problem flat plate shear flow incompressible fluid considered solutions boundarylayer thickness skin friction velocity distribution boundary layer obtained karman-pohlhausen technique comparison boundary layer uniform flow also made show effect vorticity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Preprocessing for file 5"
      ],
      "metadata": {
        "id": "awHJTec5Nqn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file for reading\n",
        "with open('/content/cranfield0005', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "id": "uNJasgBSNyx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase the text\n",
        "text = text.lower()\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords and punctuations, and blank space tokens\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuations = set(string.punctuation)\n",
        "tokens_filtered = [token for token in tokens if token not in stop_words and token not in punctuations and not token.isspace()]\n",
        "\n",
        "# Join the tokens back into a string\n",
        "text_processed5 = ' '.join(tokens_filtered)\n",
        "\n",
        "# Print the processed text\n",
        "print(text_processed5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e48547e-6e0b-4c4c-bcc7-f11fb30666f1",
        "id": "0Gf05LHIOBx2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one-dimensional transient heat conduction double-layer slab subjected linear heat input small time internal analytic solutions presented transient heat conduction composite slabs exposed one surface triangular heat rate type heating rate may occur example aerodynamic heating\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TF-IDF \n",
        "\n",
        "Since, the pre-processing of the text has already been done. I am going to use the pre-processed text to get tf-idf scores using various weighing scheme as specified."
      ],
      "metadata": {
        "id": "A6IuQpYyUGOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "ZRg7BiXvfKvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TF-IDF scores for file 1(Cranfield0001)\n",
        "\n",
        "1.Binary weighing scheme"
      ],
      "metadata": {
        "id": "AAsQa4LKUgrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed1.split('.'))\n",
        "\n",
        "# Define vectorizer with binary=True\n",
        "vectorizer = TfidfVectorizer(use_idf=True, binary=True)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"aerodynamics\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * tfidf_matrix.transpose()) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6cJI_Aia0VM",
        "outputId": "b76f821d-e443-4a7b-a31b-240dbe8aece9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'aerodynamics': [0.01666667 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667\n",
            " 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667\n",
            " 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667\n",
            " 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667\n",
            " 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667\n",
            " 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667\n",
            " 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667\n",
            " 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667\n",
            " 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667\n",
            " 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. By Raw Count weighing scheme"
      ],
      "metadata": {
        "id": "JLrUO-stb9_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed1.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=True, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"aerodynamics\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * tfidf_matrix.transpose()) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1W9SpBccFOJ",
        "outputId": "8de43e75-289d-417a-ecb0-faa22c974847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'aerodynamics': [0.01265823 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823\n",
            " 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823\n",
            " 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823\n",
            " 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823\n",
            " 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823\n",
            " 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823\n",
            " 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823\n",
            " 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823\n",
            " 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823\n",
            " 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823 0.01265823]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Term Frequency weighing"
      ],
      "metadata": {
        "id": "Ok5G7rjirhRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed1.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=False, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get term frequency values\n",
        "term_freq_values = tfidf_matrix[0]\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"aerodynamics\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, term_freq_values) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "id": "Q71Au-GBfVQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6997280f-50ae-4cf8-ffb5-3c9732df3f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'aerodynamics': 0.012658227848101266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Log Normalization weighing"
      ],
      "metadata": {
        "id": "7jkxXicZrqSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed1.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=False, norm='l2', sublinear_tf=True)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get log-normalized term frequency values\n",
        "log_term_freq_values = np.log10(tfidf_matrix[0] + 1)\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"aerodynamics\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, log_term_freq_values) / np.sum(log_term_freq_values)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8KJz7Rwr2oi",
        "outputId": "a399faa5-74eb-4d44-981e-ea3d03ef3c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'aerodynamics': 0.014391218481245404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Double normalization"
      ],
      "metadata": {
        "id": "HMiGLr_1sV8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed1.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=True, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get double-normalized term frequency values\n",
        "max_term_freq_values = np.max(tfidf_matrix, axis=1)\n",
        "double_norm_term_freq_values = 0.5 + 0.5 * (tfidf_matrix.T / max_term_freq_values).T\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"aerodynamics\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * double_norm_term_freq_values.transpose()) / np.sum(double_norm_term_freq_values, axis=1)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhjGjehgsduz",
        "outputId": "ac8b479b-6c08-4aa6-a4b4-ed57169ed840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'aerodynamics': [0.01583113 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113\n",
            " 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113\n",
            " 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113\n",
            " 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113\n",
            " 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113\n",
            " 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113\n",
            " 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113\n",
            " 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113\n",
            " 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113\n",
            " 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113 0.01583113]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TF-IDF scores for file 2 (cranfield0002)"
      ],
      "metadata": {
        "id": "u1Ekdr5JtYL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Binary weighing"
      ],
      "metadata": {
        "id": "sn2n_eapvUVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed2.split('.'))\n",
        "\n",
        "# Define vectorizer with binary=True\n",
        "vectorizer = TfidfVectorizer(use_idf=True, binary=True)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"boundary\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * tfidf_matrix.transpose()) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf02051-957a-4a14-e59c-88c909a017fe",
        "id": "YhxKzK9Qvarm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'boundary': [0.01449275 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275\n",
            " 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275\n",
            " 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275\n",
            " 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275\n",
            " 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275\n",
            " 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275\n",
            " 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275\n",
            " 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275\n",
            " 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275\n",
            " 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275\n",
            " 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275 0.01449275\n",
            " 0.01449275 0.01449275 0.01449275]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Raw Count weighing"
      ],
      "metadata": {
        "id": "xGSTUw1AvnKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed2.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=True, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"boundary\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * tfidf_matrix.transpose()) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89731c02-0370-46b8-b077-564c5f7e47b8",
        "id": "40FmnYkDvw4z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'boundary': [0.04310345 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345\n",
            " 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345\n",
            " 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345\n",
            " 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345\n",
            " 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345\n",
            " 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345\n",
            " 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345\n",
            " 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345\n",
            " 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345\n",
            " 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345\n",
            " 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345 0.04310345\n",
            " 0.04310345 0.04310345 0.04310345]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Term Frequency weighing"
      ],
      "metadata": {
        "id": "SwhEkRMdwC1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed2.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=False, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get term frequency values\n",
        "term_freq_values = tfidf_matrix[0]\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"boundary\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, term_freq_values) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abef0a74-266d-4c17-ebc7-76c31f1d8497",
        "id": "vCSdZ7W3wHKF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'boundary': 0.04310344827586207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Log Normalization weighing "
      ],
      "metadata": {
        "id": "8ic8TeqGwXOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed2.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=False, norm='l2', sublinear_tf=True)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get log-normalized term frequency values\n",
        "log_term_freq_values = np.log10(tfidf_matrix[0] + 1)\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"boundary\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, log_term_freq_values) / np.sum(log_term_freq_values)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069be8b3-4589-443a-c58e-49b63a11f74e",
        "id": "nxGbbBzBwcvB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'boundary': 0.026496926096291475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Double Normalization"
      ],
      "metadata": {
        "id": "c9DoOVIvxlnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed2.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=True, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get double-normalized term frequency values\n",
        "max_term_freq_values = np.max(tfidf_matrix, axis=1)\n",
        "double_norm_term_freq_values = 0.5 + 0.5 * (tfidf_matrix.T / max_term_freq_values).T\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"boundary\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * double_norm_term_freq_values.transpose()) / np.sum(double_norm_term_freq_values, axis=1)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258cabec-faeb-4c00-f2ee-33d157179968",
        "id": "DiM78mw-xqhe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'boundary': [0.02075472 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472\n",
            " 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472\n",
            " 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472\n",
            " 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472\n",
            " 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472\n",
            " 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472\n",
            " 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472\n",
            " 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472\n",
            " 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472\n",
            " 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472\n",
            " 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472 0.02075472\n",
            " 0.02075472 0.02075472 0.02075472]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tf-idf for file 3(cranfield0003)"
      ],
      "metadata": {
        "id": "MVag7Ip-0J1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. binary weighing scheme"
      ],
      "metadata": {
        "id": "QQK8Zmnd0Rrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed3.split('.'))\n",
        "\n",
        "# Define vectorizer with binary=True\n",
        "vectorizer = TfidfVectorizer(use_idf=True, binary=True)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"flow\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * tfidf_matrix.transpose()) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e287a16b-8374-4645-d47d-1b8eb5db51c7",
        "id": "Cvy7GgeP0ZoZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'flow': [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
            " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
            " 0.07142857 0.07142857]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Raw Count weighting"
      ],
      "metadata": {
        "id": "xh130Fvo1Jt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed3.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=True, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"flow\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * tfidf_matrix.transpose()) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a9fa0a-1609-408d-8ce3-03434e2741ae",
        "id": "dQP_fzJx1Ouw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'flow': [0.11764706 0.11764706 0.11764706 0.11764706 0.11764706 0.11764706\n",
            " 0.11764706 0.11764706 0.11764706 0.11764706 0.11764706 0.11764706\n",
            " 0.11764706 0.11764706]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Term frequency weighting"
      ],
      "metadata": {
        "id": "rDmbor1iB5Tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed3.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=False, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get term frequency values\n",
        "term_freq_values = tfidf_matrix[0]\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"flow\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, term_freq_values) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6417fd19-56fb-468f-a832-86b2b9c29222",
        "id": "gZvM2dC_B-Le"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'flow': 0.11764705882352941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Log Normalization"
      ],
      "metadata": {
        "id": "W4jKSJqSCGJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed3.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=False, norm='l2', sublinear_tf=True)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get log-normalized term frequency values\n",
        "log_term_freq_values = np.log10(tfidf_matrix[0] + 1)\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"flow\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, log_term_freq_values) / np.sum(log_term_freq_values)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f94a63-600e-4088-cd05-179ffd7dccac",
        "id": "eodQ2zrgCTPa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'flow': 0.10083270832811332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Double log normalization"
      ],
      "metadata": {
        "id": "xfpHROb1Clvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed3.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=True, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get double-normalized term frequency values\n",
        "max_term_freq_values = np.max(tfidf_matrix, axis=1)\n",
        "double_norm_term_freq_values = 0.5 + 0.5 * (tfidf_matrix.T / max_term_freq_values).T\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"flow\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * double_norm_term_freq_values.transpose()) / np.sum(double_norm_term_freq_values, axis=1)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9547c9-b5b7-4eea-eec9-234773506d35",
        "id": "BTW_W8sECzzm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'flow': [0.08888889 0.08888889 0.08888889 0.08888889 0.08888889 0.08888889\n",
            " 0.08888889 0.08888889 0.08888889 0.08888889 0.08888889 0.08888889\n",
            " 0.08888889 0.08888889]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tf-idf for file 4(cranfield 0004)"
      ],
      "metadata": {
        "id": "WcYo6UuN6jjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Binary weighting scheme"
      ],
      "metadata": {
        "id": "4n51XsRH6qbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed4.split('.'))\n",
        "\n",
        "# Define vectorizer with binary=True\n",
        "vectorizer = TfidfVectorizer(use_idf=True, binary=True)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"shear\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * tfidf_matrix.transpose()) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c15a01b-9d2d-40f4-ecac-0bec4c6bc114",
        "id": "TNNLQh6D7MgM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'shear': [0.02941176 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176\n",
            " 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176\n",
            " 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176\n",
            " 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176\n",
            " 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176\n",
            " 0.02941176 0.02941176 0.02941176 0.02941176]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Raw Count weighting"
      ],
      "metadata": {
        "id": "Pph9tagt7dMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed4.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=True, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"shear\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * tfidf_matrix.transpose()) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b235f543-f0fe-4570-9edb-6bd46aaf2552",
        "id": "raaMC3MY778M"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'shear': [0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n",
            " 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n",
            " 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n",
            " 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n",
            " 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n",
            " 0.04347826 0.04347826 0.04347826 0.04347826]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Term frequency weighting"
      ],
      "metadata": {
        "id": "FiVsLh348a5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed4.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=False, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get term frequency values\n",
        "term_freq_values = tfidf_matrix[0]\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"shear\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, term_freq_values) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25de6aec-6c07-4287-a951-8a35f5d1319b",
        "id": "dkLBOdk78gZd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'shear': 0.043478260869565216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Log normalization weighting"
      ],
      "metadata": {
        "id": "nC6dVxaL8n8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed4.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=False, norm='l2', sublinear_tf=True)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get log-normalized term frequency values\n",
        "log_term_freq_values = np.log10(tfidf_matrix[0] + 1)\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"shear\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, log_term_freq_values) / np.sum(log_term_freq_values)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1223256d-97b8-45ca-8497-832948d286b1",
        "id": "ImWUWBJ882SP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'shear': 0.040755112353462505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Double log normalization"
      ],
      "metadata": {
        "id": "zY_tpslN8_Ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed4.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=True, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get double-normalized term frequency values\n",
        "max_term_freq_values = np.max(tfidf_matrix, axis=1)\n",
        "double_norm_term_freq_values = 0.5 + 0.5 * (tfidf_matrix.T / max_term_freq_values).T\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"shear\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * double_norm_term_freq_values.transpose()) / np.sum(double_norm_term_freq_values, axis=1)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e00ee9-665d-420f-e97e-cbfe22ae6e7c",
        "id": "eZbTcXC89K2W"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'shear': [0.03296703 0.03296703 0.03296703 0.03296703 0.03296703 0.03296703\n",
            " 0.03296703 0.03296703 0.03296703 0.03296703 0.03296703 0.03296703\n",
            " 0.03296703 0.03296703 0.03296703 0.03296703 0.03296703 0.03296703\n",
            " 0.03296703 0.03296703 0.03296703 0.03296703 0.03296703 0.03296703\n",
            " 0.03296703 0.03296703 0.03296703 0.03296703 0.03296703 0.03296703\n",
            " 0.03296703 0.03296703 0.03296703 0.03296703]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TF-IDF for file 5 (cranfield0005)"
      ],
      "metadata": {
        "id": "3tf8Rfeo9ueC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Binary weighting scheme"
      ],
      "metadata": {
        "id": "vLWHl2BP9224"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed5.split('.'))\n",
        "\n",
        "# Define vectorizer with binary=True\n",
        "vectorizer = TfidfVectorizer(use_idf=True, binary=True)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"transient\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * tfidf_matrix.transpose()) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3211e959-3daf-4dc8-c069-c56eb283897b",
        "id": "c7tImIqL-Cp3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'transient': [0.03448276 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276\n",
            " 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276\n",
            " 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276\n",
            " 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276\n",
            " 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Raw count weighting"
      ],
      "metadata": {
        "id": "ID_7cCd_-Q6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed5.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=True, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"transient\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * tfidf_matrix.transpose()) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "613a89f8-8e60-4d0f-c34a-6122e987ab2e",
        "id": "nx1IUIt--ZPu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'transient': [0.05405405 0.05405405 0.05405405 0.05405405 0.05405405 0.05405405\n",
            " 0.05405405 0.05405405 0.05405405 0.05405405 0.05405405 0.05405405\n",
            " 0.05405405 0.05405405 0.05405405 0.05405405 0.05405405 0.05405405\n",
            " 0.05405405 0.05405405 0.05405405 0.05405405 0.05405405 0.05405405\n",
            " 0.05405405 0.05405405 0.05405405 0.05405405 0.05405405]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Term frequency weighting"
      ],
      "metadata": {
        "id": "ITvS3Ib1-hPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed5.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=False, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get term frequency values\n",
        "term_freq_values = tfidf_matrix[0]\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"transient\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, term_freq_values) / np.sum(tfidf_matrix)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f070b37a-16e7-4d20-c2f5-1fcb548ce084",
        "id": "sCfNoQZw-vqn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'transient': 0.05405405405405406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. log normalization"
      ],
      "metadata": {
        "id": "5GrAstQ8-5cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed5.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=False, norm='l2', sublinear_tf=True)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get log-normalized term frequency values\n",
        "log_term_freq_values = np.log10(tfidf_matrix[0] + 1)\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"transient\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, log_term_freq_values) / np.sum(log_term_freq_values)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a9a8d79-d797-4fb2-a763-a631f2af35f6",
        "id": "ShsKRXjt_G6-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'transient': 0.04862915542698041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Double log normalization"
      ],
      "metadata": {
        "id": "tsWFbwUl_RKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Preprocessed document into lines\n",
        "preprocessed_doc = \" \".join(text_processed5.split('.'))\n",
        "\n",
        "# Define vectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=True, norm=None, binary=False)\n",
        "\n",
        "# Calculate TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform([preprocessed_doc]).toarray()\n",
        "\n",
        "# Get double-normalized term frequency values\n",
        "max_term_freq_values = np.max(tfidf_matrix, axis=1)\n",
        "double_norm_term_freq_values = 0.5 + 0.5 * (tfidf_matrix.T / max_term_freq_values).T\n",
        "\n",
        "# Get IDF values\n",
        "idf_values = vectorizer.idf_\n",
        "\n",
        "# Calculate TF-IDF score for a given query\n",
        "query = \"transient\"\n",
        "query_vector = np.zeros(len(tfidf_matrix[0]))\n",
        "if query in vectorizer.vocabulary_:\n",
        "    query_vector[vectorizer.vocabulary_[query]] = 1\n",
        "tfidf_score = np.dot(query_vector, idf_values * double_norm_term_freq_values.transpose()) / np.sum(double_norm_term_freq_values, axis=1)\n",
        "print(f\"TF-IDF score for query '{query}': {tfidf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0fb255a-34d2-41ee-cd66-1bc5684ed5fc",
        "id": "7rUfbF9L_dZ4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF score for query 'transient': [0.03921569 0.03921569 0.03921569 0.03921569 0.03921569 0.03921569\n",
            " 0.03921569 0.03921569 0.03921569 0.03921569 0.03921569 0.03921569\n",
            " 0.03921569 0.03921569 0.03921569 0.03921569 0.03921569 0.03921569\n",
            " 0.03921569 0.03921569 0.03921569 0.03921569 0.03921569 0.03921569\n",
            " 0.03921569 0.03921569 0.03921569 0.03921569 0.03921569]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Jaccard Coefficient"
      ],
      "metadata": {
        "id": "1-__Xgl3Mvmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. For file 1"
      ],
      "metadata": {
        "id": "ocrxNLcwNTzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "query = 'experimental study'\n",
        "doc = text_processed1\n",
        "\n",
        "query_tokens = set(nltk.word_tokenize(query.lower()))\n",
        "doc_tokens = set(nltk.word_tokenize(doc.lower()))\n",
        "\n",
        "intersection = query_tokens.intersection(doc_tokens)\n",
        "union = query_tokens.union(doc_tokens)\n",
        "\n",
        "jaccard_coefficient = len(intersection) / len(union)\n",
        "\n",
        "print(jaccard_coefficient)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCSrpnRDMyuu",
        "outputId": "2e2fcc18-8edc-40c0-8cad-b3142b705452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03389830508474576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. For file 2"
      ],
      "metadata": {
        "id": "DUkGjMuNNbLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "query = \"incompressible fluid viscosity\"\n",
        "doc = text_processed2\n",
        "\n",
        "query_tokens = set(nltk.word_tokenize(query.lower()))\n",
        "doc_tokens = set(nltk.word_tokenize(doc.lower()))\n",
        "\n",
        "intersection = query_tokens.intersection(doc_tokens)\n",
        "union = query_tokens.union(doc_tokens)\n",
        "\n",
        "jaccard_coefficient = len(intersection) / len(union)\n",
        "\n",
        "print(jaccard_coefficient)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUQZ3NjBNdkP",
        "outputId": "77878bbe-bcfb-44ae-dddc-501a05e604c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.043478260869565216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. For file 3"
      ],
      "metadata": {
        "id": "FElYPJ5u_7wu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPvyHq0o_-_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "query = \"shear flow\"\n",
        "doc = text_processed3\n",
        "\n",
        "query_tokens = set(nltk.word_tokenize(query.lower()))\n",
        "doc_tokens = set(nltk.word_tokenize(doc.lower()))\n",
        "\n",
        "intersection = query_tokens.intersection(doc_tokens)\n",
        "union = query_tokens.union(doc_tokens)\n",
        "\n",
        "jaccard_coefficient = len(intersection) / len(union)\n",
        "\n",
        "print(jaccard_coefficient)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819e6287-0c4a-4027-cdd5-fb4e395d8454",
        "id": "KyLap2GZADuU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. For file 4"
      ],
      "metadata": {
        "id": "LnwXpi4yAKuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "query = \"boundary layer equations\"\n",
        "doc = text_processed4\n",
        "\n",
        "query_tokens = set(nltk.word_tokenize(query.lower()))\n",
        "doc_tokens = set(nltk.word_tokenize(doc.lower()))\n",
        "\n",
        "intersection = query_tokens.intersection(doc_tokens)\n",
        "union = query_tokens.union(doc_tokens)\n",
        "\n",
        "jaccard_coefficient = len(intersection) / len(union)\n",
        "\n",
        "print(jaccard_coefficient)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad306d61-2ab1-4ae0-9cae-08651db423e3",
        "id": "z5IaSaJJANqq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09090909090909091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. For file 5"
      ],
      "metadata": {
        "id": "QBQ-2u2fAlmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "query = \"transient heat\"\n",
        "doc = text_processed5\n",
        "\n",
        "query_tokens = set(nltk.word_tokenize(query.lower()))\n",
        "doc_tokens = set(nltk.word_tokenize(doc.lower()))\n",
        "\n",
        "intersection = query_tokens.intersection(doc_tokens)\n",
        "union = query_tokens.union(doc_tokens)\n",
        "\n",
        "jaccard_coefficient = len(intersection) / len(union)\n",
        "\n",
        "print(jaccard_coefficient)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214538fc-47eb-46b2-f486-5d72daa755a6",
        "id": "fLgAS6j_AqDf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07142857142857142\n"
          ]
        }
      ]
    }
  ]
}